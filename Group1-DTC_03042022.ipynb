{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Translation Challenge: Group 1\n",
    "### Source: https://www.codementor.io/spark/tutorial/building-a-recommender-with-apache-spark-python-example-app-part1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a SparkContext configured for local mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sc = pyspark.SparkContext(\"local[*]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File download\n",
    "Small: 100,000 ratings and 2,488 tag applications applied to 8,570 movies by 706 users. Last updated 4/2015.   \n",
    "Full: 21,000,000 ratings and 470,000 tag applications applied to 27,000 movies by 230,000 users. Last updated 4/2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_url = \"http://files.grouplens.org/datasets/movielens/ml-latest.zip\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download location(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datasets_path = os.path.join(\"/home/jovyan\", \"work\")\n",
    "full_dataset_path = os.path.join(datasets_path, \"ml-latest.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "full_f = urllib.request.urlretrieve(full_dataset_url, full_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(full_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and parsing datasets\n",
    "We can read in each of the files and create an RDD consisting of parsed lines. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27753444 recommendations in the complete dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 307, 3.5), (1, 481, 3.5), (1, 1091, 1.5)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the full ratings dataset file\n",
    "complete_ratings_file = os.path.join(datasets_path, \"ml-latest\", \"ratings.csv\")\n",
    "complete_ratings_raw_data = sc.textFile(complete_ratings_file)\n",
    "complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0]\n",
    "\n",
    "# Parse to create the tuple.\n",
    "complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line != complete_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]), \n",
    "                                                           int(tokens[1]), \n",
    "                                                           float(tokens[2]))).cache()\n",
    "\n",
    "print (f\"There are {complete_ratings_data.count()} recommendations in the complete dataset\")\n",
    "complete_ratings_data.take(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### movies.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58098 movies in the complete dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 'Toy Story (1995)', 'Adventure|Animation|Children|Comedy|Fantasy'),\n",
       " (2, 'Jumanji (1995)', 'Adventure|Children|Fantasy'),\n",
       " (3, 'Grumpier Old Men (1995)', 'Comedy|Romance')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the full movies dataset file\n",
    "complete_movies_file = os.path.join(datasets_path, \"ml-latest\", \"movies.csv\")\n",
    "complete_movies_raw_data = sc.textFile(complete_movies_file)\n",
    "complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]\n",
    "\n",
    "# Parse to create the tuple\n",
    "complete_movies_data = complete_movies_raw_data.filter(lambda line: line != complete_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]), tokens[1], tokens[2])).cache()\n",
    "\n",
    "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]), x[1]))\n",
    "print (f\"There are {complete_movies_titles.count()} movies in the complete dataset\")\n",
    "complete_movies_data.take(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting ALS parameters using the full dataset\n",
    "In order to determine the best ALS parameters, we will use the full dataset. We need first to split it into train, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source uses seed=0L, which is the previous version of python (2.x)\n",
    "# 0L should be written as 0 from now on\n",
    "training_RDD, validation_RDD, test_RDD = complete_ratings_data.randomSplit([6.0, 2.0, 2.0], seed=0)\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.833819646989376\n",
      "For rank 8 the RMSE is 0.8282050974334421\n",
      "For rank 12 the RMSE is 0.8196790075634646\n",
      "The best model was trained with rank 12\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float(\"inf\")\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1]) ** 2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print (f\"For rank {rank} the RMSE is {error}\")\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print (f\"The best model was trained with rank {best_rank}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split it into training and test datasets.\n",
    "training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=0)\n",
    "\n",
    "complete_model = ALS.train(training_RDD, best_rank, seed=seed, \\\n",
    "                           iterations=iterations, lambda_=regularization_parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.8167046400802203\n"
     ]
    }
   ],
   "source": [
    "# On to the test set.\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1]) ** 2).mean())\n",
    "\n",
    "print (f\"For testing data the RMSE is {error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1])) / nratings)\n",
    "\n",
    "movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users with Own Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings_1 = [\n",
    "     (0,55247,2), # Into the Wild (2007) - Action|Adventure|Drama\n",
    "     (0,55245,1), # - Good Luck Chuck (2007) - Comedy|Romance\n",
    "     (0,56757,1), # Sweeney Todd: The Demon Barber of Fleet Street (2007) - Drama|Horror|Musical|Thriller\n",
    "     (0,52973,3), # Knocked Up (2007) - Comedy|Drama|Romance \n",
    "     (0,122900,5), # Ant-Man (2015) - Action|Adventure|Sci-Fi\n",
    "     (0,122918,5), # Guardians of the Galaxy 2 (2017) - Action|Adventure|Sci-Fi \n",
    "     (0,22924,5), # X-Men: Apocalypse (2016) - Action|Adventure|Fantasy|Sci-Fi\n",
    "     (0,1197,5), # Princess Bride, The (1987) - Action|Adventure|Comedy|Fantasy|Romance\n",
    "     (0,1198,4), # Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981) - Action|Adventure\n",
    "     (0,4306,5) # Shrek (2001) - Adventure|Animation|Children|Comedy|Fantasy|RomanceShrek (2001) - Adventure|Animation|Children|Comedy|Fantasy|Romance\n",
    "]\n",
    "\n",
    "new_user_ratings_2 = [\n",
    "    (0,8694,5), # Black Panther (2017)\n",
    "    (0,6733,4), # Speed Racer (2008)\n",
    "    (0,8029,4), # Man with the Iron Fists, The (2012)\n",
    "    (0,9354,2), # The Infiltrator (2016)\n",
    "    (0,6907,3), # Twilight (2008)\n",
    "    (0,6905,1), # Bolt (2008)\n",
    "    (0,1754,1), # Heart Condition (1990)\n",
    "    (0,8026,5), # Flight (2012)\n",
    "    (0,4942,3), # Man on Fire (2004)\n",
    "    (0,4946,2) # Mean Girls (2004)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User 1 - Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the user 1 specific model.\n",
    "\n",
    "new_user_ratings_RDD_1 = sc.parallelize(new_user_ratings_1)\n",
    "complete_data_with_new_ratings_RDD_1 = complete_ratings_data.union(new_user_ratings_RDD_1)\n",
    "new_ratings_model_1 = ALS.train(complete_data_with_new_ratings_RDD_1, best_rank, seed=seed,\n",
    "                                iterations=iterations, lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP recommended movies user 1 (with more than 25 reviews):\n",
      "('A LEGO Brickumentary (2015)', 4.9072186228918, 25)\n",
      "(\"Batman Beyond Darwyn Cooke's Batman 75th Anniversary Short (2014)\", 4.878582318659377, 29)\n",
      "('Star Wars: Episode IV - A New Hope (1977)', 4.86727962276997, 81815)\n",
      "('Rabbit Seasoning (1952)', 4.7926994421592255, 45)\n",
      "('Duck Dodgers in the 24½th Century (1953)', 4.791536831712013, 41)\n",
      "('Star Wars: Episode V - The Empire Strikes Back (1980)', 4.779312121026229, 65822)\n",
      "('Patton Oswalt: Werewolves and Lollipops (2007)', 4.773475909277394, 56)\n",
      "('Rush: Beyond the Lighted Stage (2010)', 4.737600640652225, 58)\n",
      "(\"Star Wars Uncut: Director's Cut (2012)\", 4.7246466566674705, 48)\n",
      "('\"Garfield Christmas Special', 4.719041256668154, 43)\n",
      "(\"Wallace & Gromit's Cracking Contraptions (2002)\", 4.713192258986728, 29)\n",
      "('Saturday Night Live: The Best of Will Ferrell (2002)', 4.698081521845628, 26)\n",
      "('Marvel One-Shot: All Hail the King (2014)', 4.6971995547942145, 37)\n",
      "('Star Wars: Episode VI - Return of the Jedi (1983)', 4.677835136847617, 66023)\n",
      "('Doctor Who: A Christmas Carol (2010)', 4.621458294465202, 271)\n"
     ]
    }
   ],
   "source": [
    "new_user_ID_1 = 0\n",
    "\n",
    "# Remove rated movies.\n",
    "new_user_ratings_ids_1 = map(lambda x: x[1], new_user_ratings_1)\n",
    "new_user_unrated_movies_RDD_1 = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids_1).map(lambda x: (new_user_ID_1, x[0])))\n",
    "\n",
    "# Get predicted recommendations.\n",
    "new_user_recommendations_RDD_1 = new_ratings_model_1.predictAll(new_user_unrated_movies_RDD_1)\n",
    "\n",
    "# Join datasets for information.\n",
    "new_user_recommendations_rating_RDD_1 = new_user_recommendations_RDD_1.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD_1 = \\\n",
    "    new_user_recommendations_rating_RDD_1.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "\n",
    "# Parse results.\n",
    "new_user_recommendations_rating_title_and_count_RDD_1 = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD_1.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "\n",
    "# Filter for movies with, at least, 25 ratings.\n",
    "top_movies_1_25 = new_user_recommendations_rating_title_and_count_RDD_1.filter(lambda r: r[2] >= 25).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print (\"TOP recommended movies user 1 (with more than 25 reviews):\\n{}\".format(\"\\n\".join(map(str, top_movies_1_25))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User 1 - Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP recommended movies user 1 (with more than 100 reviews):\n",
      "('Star Wars: Episode IV - A New Hope (1977)', 4.86727962276997, 81815)\n",
      "('Star Wars: Episode V - The Empire Strikes Back (1980)', 4.779312121026229, 65822)\n",
      "('Star Wars: Episode VI - Return of the Jedi (1983)', 4.677835136847617, 66023)\n",
      "('Doctor Who: A Christmas Carol (2010)', 4.621458294465202, 271)\n",
      "('Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)', 4.559795936437209, 63505)\n",
      "(\"Empire of Dreams: The Story of the 'Star Wars' Trilogy (2004)\", 4.55031659246357, 135)\n",
      "('Star Trek IV: The Voyage Home (1986)', 4.5034313214209245, 15376)\n",
      "('Incredibles 2 (2018)', 4.495378964785873, 857)\n",
      "('\"Princess Bride', 4.471959937627585, 42878)\n",
      "('Avengers: Infinity War - Part I (2018)', 4.4582505762742315, 2668)\n",
      "('Indiana Jones and the Last Crusade (1989)', 4.40410285133046, 42043)\n",
      "('Superman/Batman: Public Enemies (2009)', 4.40091630863577, 174)\n",
      "('\"Avengers', 4.39678180011704, 17700)\n",
      "('Star Trek II: The Wrath of Khan (1982)', 4.395321894815153, 18024)\n",
      "('Raiders of the Lost Ark: The Adaptation (1989)', 4.355743956121027, 1303)\n"
     ]
    }
   ],
   "source": [
    "# Filter for movies with, at least, 100 ratings.\n",
    "top_movies_1_100 = new_user_recommendations_rating_title_and_count_RDD_1.filter(lambda r: r[2] >= 100).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print (\"TOP recommended movies user 1 (with more than 100 reviews):\\n{}\".format(\"\\n\".join(map(str, top_movies_1_100))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User 2 - Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the user 2 specific model.\n",
    "\n",
    "new_user_ratings_RDD_2 = sc.parallelize(new_user_ratings_2)\n",
    "complete_data_with_new_ratings_RDD_2 = complete_ratings_data.union(new_user_ratings_RDD_2)\n",
    "new_ratings_model_2 = ALS.train(complete_data_with_new_ratings_RDD_2, best_rank, seed=seed,\n",
    "                                iterations=iterations, lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP recommended movies user 2 (with more than 25 reviews):\n",
      "('\"Red and the White', 4.497839207050969, 47)\n",
      "('Runaway Brain (1995) ', 4.472564235039869, 30)\n",
      "('Он вам не Димон (2017)', 4.427011957799822, 26)\n",
      "('Tarzan and His Mate (1934)', 4.417219320345462, 54)\n",
      "('Connections (1978)', 4.371960581473736, 49)\n",
      "('Mafioso (1962)', 4.3638143882188, 25)\n",
      "('When a Woman Ascends the Stairs (Onna ga kaidan wo agaru toki) (1960)', 4.250751287714202, 42)\n",
      "('Sweeney Todd: The Demon Barber of Fleet Street (1982)', 4.2201720432124725, 28)\n",
      "('7th Heaven (Seventh Heaven) (1927)', 4.20491500177358, 28)\n",
      "('La Belle Verte (1996)', 4.202270846296766, 41)\n",
      "('\"Spiders Part 1: The Golden Lake', 4.174188638248877, 45)\n",
      "('\"Clock', 4.172444767759022, 55)\n",
      "('\"Brighter Summer Day', 4.16463770874708, 54)\n",
      "('\"Last Command', 4.1635402284046314, 30)\n",
      "('You Were Never Lovelier (1942)', 4.152178086197343, 42)\n"
     ]
    }
   ],
   "source": [
    "new_user_ID_2 = 0\n",
    "\n",
    "# Remove rated movies\n",
    "new_user_ratings_ids_2 = map(lambda x: x[1], new_user_ratings_2)\n",
    "new_user_unrated_movies_RDD_2 = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids_2).map(lambda x: (new_user_ID_2, x[0])))\n",
    "\n",
    "# Get predicted recommendations\n",
    "new_user_recommendations_RDD_2 = new_ratings_model_2.predictAll(new_user_unrated_movies_RDD_2)\n",
    "\n",
    "# Join datasets for information\n",
    "new_user_recommendations_rating_RDD_2 = new_user_recommendations_RDD_2.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD_2 = \\\n",
    "    new_user_recommendations_rating_RDD_2.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "\n",
    "# Parse results\n",
    "new_user_recommendations_rating_title_and_count_RDD_2 = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD_2.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "\n",
    "# Filter for at least 25 ratings\n",
    "top_movies_2_25 = new_user_recommendations_rating_title_and_count_RDD_2.filter(lambda r: r[2] >= 25).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print (\"TOP recommended movies user 2 (with more than 25 reviews):\\n{}\".format(\"\\n\".join(map(str, top_movies_2_25))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User 2 - Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP recommended movies user 2 (with more than 100 reviews):\n",
      "('Early Summer (Bakushû) (1951)', 4.130987910702434, 173)\n",
      "('Trouble in Paradise (1932)', 4.054620773758919, 468)\n",
      "('Seven Chances (1925)', 4.02052387194487, 222)\n",
      "('Late Spring (Banshun) (1949)', 4.019431336366936, 283)\n",
      "('Midnight (1939)', 3.962112966412402, 102)\n",
      "('\"Navigator', 3.959501327846365, 247)\n",
      "('\"World of Apu', 3.946843427120903, 832)\n",
      "('\"Crowd', 3.9441721119690785, 109)\n",
      "('Story of G.I. Joe (1945)', 3.9322354707216878, 103)\n",
      "('\"47 Samurai (Chûshingura) (Loyal 47 Ronin', 3.9286109563723315, 149)\n",
      "('\"Miracle of Morgan\\'s Creek', 3.9136347785523293, 101)\n",
      "('Greed (1924)', 3.9035436479976444, 219)\n",
      "(\"I Know Where I'm Going! (1945)\", 3.8841247331342634, 269)\n",
      "('Day of Wrath (Vredens dag) (1943)', 3.865905544652129, 200)\n",
      "('\"Dr. Mabuse: The Gambler (Dr. Mabuse', 3.8566002942978477, 175)\n"
     ]
    }
   ],
   "source": [
    "# Filter for at least 100 ratings\n",
    "top_movies_2_100 = new_user_recommendations_rating_title_and_count_RDD_2.filter(lambda r: r[2] >= 100).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print (\"TOP recommended movies user 2 (with more than 100 reviews):\\n{}\".format(\"\\n\".join(map(str, top_movies_2_100))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
